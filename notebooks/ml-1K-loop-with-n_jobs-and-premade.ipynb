{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515b48b7",
   "metadata": {},
   "source": [
    "# *ml-1K-loop-with-n_jobs-and-premade.ipynb*\n",
    "\n",
    "# Running models sequentially, but each model uses n_jobs=-1 for parallelization; use premade train/val datasets\n",
    "\n",
    "Version 1K: Accomodates new model architectures. Reads in premade train and val datasets for each fold. (This makes the \"Assembling datasets\" portion much faster!)\n",
    "\n",
    "This is a work-in-progress-notebook. Currently, it allows us to: specify a models bank for 160 Random Forest and Extra Trees models; assemble the datasets for different folds of year-wise cross-validation; run the models for 12 combinations of region, crop, compositing scheme, and in-season date; and record results (accuracies and uncertainties) in csv files.\n",
    "\n",
    "Function definitions at the top of the notebook; then sequential model runs (but each RF/ET run using parallel n_jobs=-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d28217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27790d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models_bank(architecture):\n",
    "    models_bank = {}\n",
    "    increment = 0\n",
    "    if architecture in ('RF','ET','RFET','ETRF'):\n",
    "        for n_estimators in [200, 500]:\n",
    "            for max_features in [0.05, 0.1, 0.2, 0.4, 1.0]:\n",
    "                for min_samples_split in [2, 4]:\n",
    "                    for bootstrap in [False, True]:\n",
    "                        for class_weight in [None, 'balanced']:\n",
    "\n",
    "                            increment += 1\n",
    "\n",
    "                            three_digit = str(increment).zfill(3)\n",
    "                            models_bank[three_digit] = {\n",
    "                                'n_estimators': n_estimators,\n",
    "                                'max_features': max_features,\n",
    "                                'bootstrap': bootstrap,\n",
    "                                'min_samples_split': min_samples_split,\n",
    "                                'class_weight': class_weight,\n",
    "                                'n_jobs': -1\n",
    "                            }\n",
    "\n",
    "    if architecture in ('LR'):\n",
    "        # 50 regularized models\n",
    "        for l1_ratio in [0, 0.1, 0.5, 0.9, 1]:\n",
    "            for C in [1, 10**-2, 10**-4, 10**-6, 10**-8]:\n",
    "                for class_weight in [None, 'balanced']:\n",
    "                    increment += 1\n",
    "                    three_digit = str(increment).zfill(3)\n",
    "                    models_bank[three_digit] = {\n",
    "                        'solver': 'saga',\n",
    "                        'penalty': 'elasticnet',\n",
    "                        'l1_ratio': l1_ratio,\n",
    "                        'C': C,\n",
    "                        'class_weight': class_weight,\n",
    "                        'max_iter': 100000,\n",
    "                        'random_state': 19\n",
    "                    }\n",
    "        # 2 nonregularized models\n",
    "        for class_weight in [None, 'balanced']:\n",
    "            increment += 1\n",
    "            three_digit = str(increment).zfill(3)\n",
    "            models_bank[three_digit] = {\n",
    "                'solver': 'saga',\n",
    "                'penalty': 'none',\n",
    "                'class_weight': class_weight,\n",
    "                'max_iter': 20000,\n",
    "                'random_state': 19\n",
    "            }\n",
    "\n",
    "    return models_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08591a30-9eb0-4188-8946-61392af59637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_premade_X_y_train_val(training_sample_size,validation_sample_size,tile,\n",
    "                     val_year,scheme_name,crop_of_interest_id,in_season):\n",
    "\n",
    "    loc = f'../data/premade_{training_sample_size}_{validation_sample_size}'\n",
    "    strings = []\n",
    "    for arg in [tile,val_year,scheme_name,crop_of_interest_id,in_season]:\n",
    "        strings.append(f'{arg}')\n",
    "    most_of_name = '_'.join(strings) \n",
    "    \n",
    "    Xy_trainval= ['X_train', 'X_val', 'y_train', 'y_val']\n",
    "    \n",
    "    d = {}\n",
    "    for spec in Xy_trainval:\n",
    "        d[spec] = np.load(f'{loc}/{most_of_name}_{spec}.npy')\n",
    "    \n",
    "    return d['X_train'], d['X_val'], d['y_train'], d['y_val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff9b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_predict_report(model_name,\n",
    "                      model,\n",
    "                      training_sample_size,\n",
    "                      validation_sample_size,\n",
    "                      tile,\n",
    "                      years,\n",
    "                      scheme_name,\n",
    "                      crop_of_interest_id,\n",
    "                      in_season,\n",
    "                      from_premade=True\n",
    "                      ):\n",
    "    \n",
    "    # produce csv_name\n",
    "    exempt = ['years', 'model']\n",
    "    param_value_strings = [f'{model_name}',\n",
    "                      f'{training_sample_size}',\n",
    "                      f'{validation_sample_size}',\n",
    "                      f'{tile}',\n",
    "                      f'{scheme_name}',\n",
    "                      f'{crop_of_interest_id}',\n",
    "                      f'{in_season}']\n",
    "    csv_name = '_'.join(param_value_strings) +'.csv'\n",
    "\n",
    "    # check whether previously run and, if so, end the effort\n",
    "    if csv_name in os.listdir('../data/results/'):\n",
    "        return 'If you see this, the specified model was previously run.'\n",
    "\n",
    "    print(f'-- Process for {csv_name} --')\n",
    "    \n",
    "    # below is actually fitting and predicting and reporting\n",
    "    \n",
    "    conf = []\n",
    "\n",
    "    for val_year in years:\n",
    "        print('Starting a fold...')\n",
    "        print('> Assembling the datasets')\n",
    "        # NEED: X_train, y_train, X_val, y_val\n",
    "        if from_premade==True: \n",
    "            X_train, X_val, y_train, y_val = grab_premade_X_y_train_val(training_sample_size,\n",
    "                    validation_sample_size,tile,val_year,scheme_name,\n",
    "                    crop_of_interest_id,in_season)\n",
    "        \n",
    "        if from_premade!=True:\n",
    "            return 'This function in this notebook is only for from_premade=True'\n",
    "        \n",
    "        print('> Fitting the model on the training set')\n",
    "        model.fit(X_train, y_train)\n",
    "        print('> Predicting on the validation set')\n",
    "        pred = model.predict(X_val)\n",
    "\n",
    "        print('> Recording performance metrics')\n",
    "        act = y_val\n",
    "        ActPred_00 = sum((act==0) & (pred==0))\n",
    "        ActPred_01 = sum((act==0) & (pred==1))\n",
    "        ActPred_10 = sum((act==1) & (pred==0))\n",
    "        ActPred_11 = sum((act==1) & (pred==1))\n",
    "        conf_1yr = [ActPred_00, ActPred_01, ActPred_10, ActPred_11]\n",
    "\n",
    "        conf.append(conf_1yr)\n",
    "        print('Finished a fold.')\n",
    "\n",
    "    carr = np.array(conf)\n",
    "\n",
    "    carr = np.row_stack([carr,np.full((2,4),-1)])\n",
    "\n",
    "    # above we added the totals row\n",
    "    # now we need to add the columns for precision and recall\n",
    "\n",
    "    # create dataframe\n",
    "    cdf = pd.DataFrame(data = carr,\n",
    "                      index = [f'ValYear{yr}' for yr in years]+['Mean','StdE'],\n",
    "                      columns = ['ActPred_00', 'ActPred_01', \n",
    "                                 'ActPred_10', 'ActPred_11']\n",
    "                      )\n",
    "\n",
    "    cdf['Precision'] = cdf.ActPred_11 / (cdf.ActPred_01 + cdf.ActPred_11)\n",
    "    cdf['Recall'] = cdf.ActPred_11 / (cdf.ActPred_10 + cdf.ActPred_11)\n",
    "    cdf['F1'] = 2*cdf.Precision*cdf.Recall / (cdf.Precision + cdf.Recall)\n",
    "    for col in ['Precision','Recall','F1']:\n",
    "        cdf.at['Mean',col] = np.mean(cdf.loc[:'ValYear2022',col])\n",
    "        cdf.at['StdE',col] = np.std(cdf.loc[:'ValYear2022',col])\n",
    "    \n",
    "    \n",
    "    param_strings = [f'# model_name: {model_name}',\n",
    "                     f'# model: {model}',\n",
    "                      f'# training_sample_size: {training_sample_size}',\n",
    "                      f'# validation_sample_size: {validation_sample_size}',\n",
    "                      f'# tile: {tile}',\n",
    "                      f'# scheme_name: {scheme_name}',\n",
    "                      f'# crop_of_interest_id: {crop_of_interest_id}',\n",
    "                      f'# in_season: {in_season}']\n",
    "    comment = '\\n'.join(param_strings) + '\\n' \n",
    "    with open(f'../data/results/{csv_name}', 'a') as f:\n",
    "        f.write(comment)\n",
    "        cdf.to_csv(f)\n",
    "    \n",
    "    print(f'Find results in ../data/results/{csv_name}')\n",
    "    \n",
    "    return f'Find results in ../data/results/{csv_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520e105-4ab3-4aa6-8ad3-016e71032cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57807c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run models sequentially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_bank = create_models_bank('LR')\n",
    "training_sample_size = 0.001\n",
    "validation_sample_size = 0.001\n",
    "\n",
    "for tile_coiid in [('10SFH',75),('15TVG',1)]:\n",
    "    for scheme_name in ['14day','5day']:\n",
    "        for in_season in [160, 230, None]:\n",
    "            for three_digit in models_bank.keys():\n",
    "\n",
    "                ## Parameters dictionary p LOGISTIC REGRESSION\n",
    "                p = {\n",
    "\n",
    "                ## SPECIFY MODEL ##\n",
    "                'model_name': 'LR' + three_digit,\n",
    "                'model': make_pipeline(StandardScaler(),\n",
    "                                   LogisticRegression(**models_bank[three_digit])),\n",
    "                'training_sample_size': training_sample_size,\n",
    "                'validation_sample_size': validation_sample_size,\n",
    "\n",
    "                ## SPECIFY TILE AND SCHEME ##\n",
    "                'tile': tile_coiid[0],\n",
    "                'years': [2018, 2019, 2020, 2021, 2022],\n",
    "                'scheme_name': scheme_name,\n",
    "                'crop_of_interest_id': tile_coiid[1], \n",
    "                'in_season': in_season\n",
    "                }\n",
    "\n",
    "                #fit_predict_report(**p) # run with the above parameters\n",
    "                fit_predict_report(**p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df496302-f49d-4c1f-96a8-35f1c983a2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53560b-4a09-4cdc-88bd-93ef7fdffea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e51822-3565-449f-a15b-11254d69d14a",
   "metadata": {},
   "source": [
    "### Testing ground for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a35cf-699b-4c16-b8b1-99622ab1d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_bank = create_models_bank('LR')\n",
    "training_sample_size = 0.001\n",
    "validation_sample_size = 0.001\n",
    "\n",
    "for tile_coiid in [('10SFH',75),('15TVG',1)]:\n",
    "    for scheme_name in ['14day','5day']:\n",
    "        for in_season in [160, 230, None]:\n",
    "            #for three_digit in models_bank.keys():\n",
    "\n",
    "            bank_specs = { 'solver': 'saga',\n",
    "                        'penalty': 'elasticnet',\n",
    "                        'l1_ratio': 0.5,\n",
    "                        'C': 0.1,\n",
    "                        'class_weight': 'balanced',\n",
    "                        'max_iter': 100000,\n",
    "                        'random_state': 19\n",
    "                         }\n",
    "\n",
    "            ## Parameters dictionary p RANDOM FOREST\n",
    "            p = {\n",
    "\n",
    "            ## SPECIFY MODEL ##\n",
    "            'model_name': 'LRtestK_saga',\n",
    "            'model': make_pipeline(StandardScaler(),\n",
    "                                   LogisticRegression(**models_bank[three_digit])),\n",
    "            'training_sample_size': training_sample_size,\n",
    "            'validation_sample_size': validation_sample_size,\n",
    "\n",
    "            ## SPECIFY TILE AND SCHEME ##\n",
    "            'tile': tile_coiid[0],\n",
    "            'years': [2018, 2019, 2020, 2021, 2022],\n",
    "            'scheme_name': scheme_name,\n",
    "            'crop_of_interest_id': tile_coiid[1], \n",
    "            'in_season': in_season\n",
    "            }\n",
    "\n",
    "            #fit_predict_report(**p) # run with the above parameters\n",
    "            fit_predict_report(**p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84e948-7b44-438a-bddf-623a4dd58b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
