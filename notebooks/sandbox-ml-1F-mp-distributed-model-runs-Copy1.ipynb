{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515b48b7",
   "metadata": {},
   "source": [
    "# *ml-1F-mp-distributed-model-runs.ipynb*\n",
    "\n",
    "This notebook (1F) features the most successful way I've found using the multiprocessing library.\n",
    "\n",
    "A few questions remain:\n",
    "- Why do model runs seem to happen sequentially, when I've called fit_predict_report() using pool.apply_async()? Is it simply that all CPUs are working on one model at a time? (I guess that may be the most efficient way)\n",
    "- Anecdotally, this appears to run roughly just as fast as notebook ml-1G which doesn't use the multiprocessing library. Am I not taking advantage of multiprocessing properly?\n",
    "- Slowest part is \"Assembling the datasets\". I will work on refactoring this code. But I have questions anyway.\n",
    "    - Couldn't this be faster if each CPU assembled its datasets in parallel (i.e. if each CPU could work on a different model in parallel)?\n",
    "    - Do you know what causes \"Assembling the datasets\" to be so slow?\n",
    "    - Note: each time we see \"Assembling the datasets\", under the hood create_Xy_single_year() gets run five times (once for each year) and some of those numpy arrays get concatenated. Not that create_Xy_single_year() uses np.load() to read a .npy file from my data folder on /work.\n",
    "    - Note: for refactoring, my first thought is to reorganize so that assembling the datasets happens once per model ratehr than once per fold. This should cut down that runtime to 1/5 of current duration.\n",
    "\n",
    "# Running models in parallel\n",
    "\n",
    "This notebook allows us to: specify a models bank for 160 Random Forest and Extra Trees models; assemble the datasets for different folds of year-wise cross-validation; run the models for 12 combinations of region, crop, compositing scheme, and in-season date; and record results (accuracies and uncertainties) in csv files.\n",
    "\n",
    "Function definitions at the top of the notebook; then parallel model runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d28217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27790d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models_bank():\n",
    "    models_bank = {}\n",
    "    increment = 0\n",
    "    for n_estimators in [200, 500]:\n",
    "        for max_features in [0.05, 0.1, 0.2, 0.4, 1.0]:\n",
    "            for min_samples_split in [2, 4]:\n",
    "                for bootstrap in [False, True]:\n",
    "                    for class_weight in [None, 'balanced']:\n",
    "\n",
    "                        increment += 1\n",
    "\n",
    "                        three_digit = str(increment).zfill(3)\n",
    "                        models_bank[three_digit] = {\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_features': max_features,\n",
    "                            'bootstrap': bootstrap,\n",
    "                            'min_samples_split': min_samples_split,\n",
    "                            'class_weight': class_weight,\n",
    "                            'n_jobs': -1\n",
    "                        }\n",
    "\n",
    "    return models_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef01eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_single_year(tile,year,scheme_name,crop_of_interest_id,\n",
    "                          in_season=None):\n",
    "    coiid = crop_of_interest_id\n",
    "    \n",
    "    refl = np.load(f'../data/composited_interpolated/Refl_{tile}_{year}_{scheme_name}.npy')\n",
    "\n",
    "    # Determine nrf (number of reflectance features)\n",
    "    if in_season not in [160, 230, None]:\n",
    "        print('Please change in_season to 160, 230, or None.')\n",
    "        return None\n",
    "    if in_season is None:\n",
    "        nrf = refl.shape[1]\n",
    "    if in_season in [160, 230]:\n",
    "        pdsize = int(scheme_name[:-3])\n",
    "        nrf = ((in_season - 90) // pdsize) * 6 + 6\n",
    "        \n",
    "    crop = []\n",
    "    for y in range(year-4,year+1):\n",
    "        crop.append(np.load(f'../data/processed_crop/Crop_{tile}_{y}.npy')==coiid)\n",
    "\n",
    "    X = np.column_stack([refl[:,:nrf]] + crop[:-1])\n",
    "    y = crop[-1]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_multiyear(tile,\n",
    "                      years,\n",
    "                      scheme_name,\n",
    "                      crop_of_interest_id,\n",
    "                        in_season=None):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for y in years:\n",
    "        X, y = create_X_y_single_year(tile,y,scheme_name,\n",
    "                                      crop_of_interest_id,\n",
    "                                     in_season)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X = np.concatenate(X_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aa44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y(tile,\n",
    "              years,\n",
    "              scheme_name,\n",
    "              crop_of_interest_id,\n",
    "              in_season=None\n",
    "              ):\n",
    "    if type(years)==int:\n",
    "        return create_X_y_single_year(tile,\n",
    "                                      years,\n",
    "                                      scheme_name,\n",
    "                                      crop_of_interest_id,\n",
    "                                      in_season)\n",
    "    \n",
    "    return create_X_y_multiyear(tile,\n",
    "                              years,\n",
    "                              scheme_name,\n",
    "                              crop_of_interest_id,\n",
    "                              in_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff9b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_predict_report(model_name,\n",
    "                      model,\n",
    "                      training_sample_size,\n",
    "                      validation_sample_size,\n",
    "                      tile,\n",
    "                      years,\n",
    "                      scheme_name,\n",
    "                      crop_of_interest_id,\n",
    "                      in_season\n",
    "                      ):\n",
    "    \n",
    "    # produce csv_name\n",
    "    exempt = ['years', 'model']\n",
    "    param_value_strings = [f'{model_name}',\n",
    "                      f'{training_sample_size}',\n",
    "                      f'{validation_sample_size}',\n",
    "                      f'{tile}',\n",
    "                      f'{scheme_name}',\n",
    "                      f'{crop_of_interest_id}',\n",
    "                      f'{in_season}']\n",
    "    csv_name = '_'.join(param_value_strings) +'.csv'\n",
    "\n",
    "    # check whether previously run and, if so, end the effort\n",
    "    if csv_name in os.listdir('../data/results/'):\n",
    "        return 'If you see this, the specified model was previously run.'\n",
    "\n",
    "    print(f'-- Process for {csv_name} --')\n",
    "    \n",
    "    # below is actually fitting and predicting and reporting\n",
    "    \n",
    "    conf = []\n",
    "\n",
    "    for val_year in years:\n",
    "        print('Starting a fold...')\n",
    "        print('> Assembling the datasets')\n",
    "        train_years = [yr for yr in range(2018,2023) if yr!=val_year]\n",
    "\n",
    "        X_train0, y_train0 = create_X_y(tile,train_years,\n",
    "                                      scheme_name,crop_of_interest_id,\n",
    "                                       in_season)\n",
    "        X_val0, y_val0 = create_X_y(tile,val_year,\n",
    "                                  scheme_name,crop_of_interest_id,\n",
    "                                  in_season)\n",
    "\n",
    "        if training_sample_size is not None:\n",
    "            X_train, X_trsurplus, y_train, y_trsurplus = train_test_split(X_train0,\n",
    "                                                                     y_train0,\n",
    "                                                                     train_size=training_sample_size,\n",
    "                                                                     random_state=19)\n",
    "        if training_sample_size is None:\n",
    "            X_train, y_train = X_train0, y_train0\n",
    "\n",
    "        if validation_sample_size is not None:\n",
    "            X_val, X_vsurplus, y_val, y_vsurplus = train_test_split(X_val0,\n",
    "                                                                     y_val0,\n",
    "                                                                     train_size=validation_sample_size,\n",
    "                                                                     random_state=19)\n",
    "        if validation_sample_size is None:\n",
    "            X_val, y_val = X_val0, y_val0\n",
    "    \n",
    "            \n",
    "        print('> Fitting the model on the training set')\n",
    "        model.fit(X_train, y_train)\n",
    "        print('> Predicting on the validation set')\n",
    "        pred = model.predict(X_val)\n",
    "\n",
    "        print('> Recording performance metrics')\n",
    "        act = y_val\n",
    "        ActPred_00 = sum((act==0) & (pred==0))\n",
    "        ActPred_01 = sum((act==0) & (pred==1))\n",
    "        ActPred_10 = sum((act==1) & (pred==0))\n",
    "        ActPred_11 = sum((act==1) & (pred==1))\n",
    "        conf_1yr = [ActPred_00, ActPred_01, ActPred_10, ActPred_11]\n",
    "\n",
    "        conf.append(conf_1yr)\n",
    "        print('Finished a fold.')\n",
    "\n",
    "    carr = np.array(conf)\n",
    "\n",
    "    carr = np.row_stack([carr,np.full((2,4),-1)])\n",
    "\n",
    "    # above we added the totals row\n",
    "    # now we need to add the columns for precision and recall\n",
    "\n",
    "    # create dataframe\n",
    "    cdf = pd.DataFrame(data = carr,\n",
    "                      index = [f'ValYear{yr}' for yr in years]+['Mean','StdE'],\n",
    "                      columns = ['ActPred_00', 'ActPred_01', \n",
    "                                 'ActPred_10', 'ActPred_11']\n",
    "                      )\n",
    "\n",
    "    cdf['Precision'] = cdf.ActPred_11 / (cdf.ActPred_01 + cdf.ActPred_11)\n",
    "    cdf['Recall'] = cdf.ActPred_11 / (cdf.ActPred_10 + cdf.ActPred_11)\n",
    "    cdf['F1'] = 2*cdf.Precision*cdf.Recall / (cdf.Precision + cdf.Recall)\n",
    "    for col in ['Precision','Recall','F1']:\n",
    "        cdf.at['Mean',col] = np.mean(cdf.loc[:'ValYear2022',col])\n",
    "        cdf.at['StdE',col] = np.std(cdf.loc[:'ValYear2022',col])\n",
    "    \n",
    "    \n",
    "    param_strings = [f'# model_name: {model_name}',\n",
    "                     f'# model: {model}',\n",
    "                      f'# training_sample_size: {training_sample_size}',\n",
    "                      f'# validation_sample_size: {validation_sample_size}',\n",
    "                      f'# tile: {tile}',\n",
    "                      f'# scheme_name: {scheme_name}',\n",
    "                      f'# crop_of_interest_id: {crop_of_interest_id}',\n",
    "                      f'# in_season: {in_season}']\n",
    "    comment = '\\n'.join(param_strings) + '\\n' \n",
    "    with open(f'../data/results/{csv_name}', 'a') as f:\n",
    "        f.write(comment)\n",
    "        cdf.to_csv(f)\n",
    "    \n",
    "    print(f'Find results in ../data/results/{csv_name}')\n",
    "    \n",
    "    return f'Find results in ../data/results/{csv_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520e105-4ab3-4aa6-8ad3-016e71032cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7831836d-0cc9-4ce8-bf95-74be5d6e1dfb",
   "metadata": {},
   "source": [
    "## Python Multiprocessing way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812ed5a-ef0a-4b4b-948a-1a87334f87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e93d12-ac7c-4277-a0b3-7a0889f80d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584423c8-eade-4fbc-9f20-e9a1aa97d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.sched_getaffinity(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08658ed-27f9-41b8-81d9-424e2604c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    with mp.Pool(56) as pool:\n",
    "        manager = mp.Manager()\n",
    "        \n",
    "        models_bank = create_models_bank()\n",
    "        training_sample_size = 0.01\n",
    "        validation_sample_size = 0.01\n",
    "        \n",
    "        for tile_coiid in [('10SFH',75),('15TVG',1)]:\n",
    "            for scheme_name in ['14day','5day']:\n",
    "                for in_season in [160, 230, None]:\n",
    "                    for three_digit in models_bank.keys():\n",
    "\n",
    "                        ## Parameters dictionary p RANDOM FOREST\n",
    "                        p = {\n",
    "\n",
    "                        ## SPECIFY MODEL ##\n",
    "                        'model_name': 'RF' + three_digit,\n",
    "                        'model': RandomForestClassifier(**models_bank[three_digit]),\n",
    "                        'training_sample_size': training_sample_size,\n",
    "                        'validation_sample_size': validation_sample_size,\n",
    "\n",
    "                        ## SPECIFY TILE AND SCHEME ##\n",
    "                        'tile': tile_coiid[0],\n",
    "                        'years': [2018, 2019, 2020, 2021, 2022],\n",
    "                        'scheme_name': scheme_name,\n",
    "                        'crop_of_interest_id': tile_coiid[1], \n",
    "                        'in_season': in_season\n",
    "                        }\n",
    "\n",
    "                        #fit_predict_report(**p) # run with the above parameters\n",
    "                        pool.apply_async(fit_predict_report, args=p.values()).get()\n",
    "\n",
    "                        ## Parameters dictionary p EXTRA TREES\n",
    "                        p = {\n",
    "\n",
    "                        ## SPECIFY MODEL ##\n",
    "                        'model_name': 'ET' + three_digit,\n",
    "                        'model': ExtraTreesClassifier(**models_bank[three_digit]),\n",
    "                        'training_sample_size': training_sample_size,\n",
    "                        'validation_sample_size': validation_sample_size,\n",
    "\n",
    "                        ## SPECIFY TILE AND SCHEME ##\n",
    "                        'tile': tile_coiid[0],\n",
    "                        'years': [2018, 2019, 2020, 2021, 2022],\n",
    "                        'scheme_name': scheme_name,\n",
    "                        'crop_of_interest_id': tile_coiid[1], \n",
    "                        'in_season': in_season\n",
    "                        }\n",
    "\n",
    "                        pool.apply_async(fit_predict_report, args=p.values()).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ee819-78d8-4714-ae18-591adbb070a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
