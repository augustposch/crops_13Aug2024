{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10b25df",
   "metadata": {},
   "source": [
    "# Explanation of Mathematical Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34fae24",
   "metadata": {},
   "source": [
    "In machine learning, our goal is to approximate a function $f:X \\rightarrow Y$ \n",
    "using a training set $\\{x_i,y_i\\}_{i=1}^N$. Our project is a classification problem - for now, a binary classification of Almonds or Not Almonds - so $Y=\\{0,1\\}$ where $1$ indicates Almonds. In our project, $X$ is the set of pixels in a given year. Given a pixel $x_i \\in X$, the function $f$ assigns it the correct label $y_i \\in Y$.\n",
    "\n",
    "Each pixel $x_i$ has features representing the remotely-sensed reflectance within different color bands and different time periods (define sets $B$ and $P$, respectively). In our task, we divide the year into, say, $|P|=25$ temporal periods, and we have $|B|=6$ bands. Each reflectance is a real number, so $X$ is a subset of $\\mathbb{R}^{150}$. More formally, $X \\subset \\mathbb{R}^{|P||B|} = \\mathbb{R}^{25 \\cdot 6} = \\mathbb{R}^{150}$.\n",
    "\n",
    "The in-season aspect of our project means that we define a cutoff day of the year $c$, so that $P_c \\subset P$ is the set of periods occuring before cutoff day $c$. Suppose $c=180$ (late June) and that there are 12 full periods before day 180. Then our input space is $X_{180} \\subset \\mathbb{R}^{|P_{180}||B|} = \\mathbb{R}^{12 \\cdot 6} = \\mathbb{R}^{72}$. That is, we are attempting to label these pixels based on only 72 features instead of 150 features. In general, let us say that $f_c:X_c \\rightarrow Y$ is our in-season function.\n",
    "\n",
    "Our goal is to compare 8 different machine learning architectures to see which can best approximate $f$, and, for a few different values of in-season cutoff day $c$, which architectures can best approximate $f_c$.\n",
    "\n",
    "How do we know which candidate function $\\hat{f}$ best approximates $f$? What do we mean by \"best\"? Machine learning is about finding an $\\hat{f}$ that generalizes well from our finite training data $S$ to the infinite space $X \\times Y$ of all potential data. To measure how closely our candidate function predicts the true label, we use an accuracy function $\\text{Acc}(y,\\hat{f}(x))$.   To capture \"generalizes well\", we want to find, out of all possible functions $\\mathcal{F}$, the function $f^*$ that maximizes expected accuracy on all potential data.\n",
    "\n",
    "$$f^* = \\arg\\max_{f \\in \\mathcal{F}} \\mathbb{E}_{(x,y)\\in X \\times Y} [\\text{Acc}(y,f(x))]$$\n",
    "\n",
    "In practice, we must limit ourselves to a subset of functions $F \\subset \\mathcal{F}$ (in our case, $F$ encompassses 8 specific architectures), and to the data we have available, $S$. So in practice in machine learning, we find, out of our chosen architectures, which function maximizes *empirical* expected accuracy.\n",
    "\n",
    "$$f^* = \\arg\\max_{f \\in F} \\mathbb{E}_{(x_i,y_i)\\in S} [\\text{Acc}(y_i,f(x_i))]$$\n",
    "\n",
    "This project aims to find the above $f^*$ for the crop classification problem. \n",
    "\n",
    "Furthermore, we have multiple kinds of accuracy to consider, and we want not only expected value, but also the variance of the accuracy. We will explore all of these angles in this project, getting a sense of the strengths of each model with regards to uncertainty and all types of accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pygdal-skl)",
   "language": "python",
   "name": "pygdal-skl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
