{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: temporally composite one tile for one period.\n",
    "\n",
    "#(also see how long it takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead2cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ad0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068343ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_granule(granule_path,\n",
    "                        mark_if_clouds=True,\n",
    "                        mark_if_shadow=True,\n",
    "                        mark_if_adjacent=True,\n",
    "                        mark_if_snow=False):\n",
    "\n",
    "    granule = granule_path[-34:]\n",
    "    \n",
    "    fmask_tiff = f'{granule}.Fmask.tif'\n",
    "    fmask_path = f'{granule_path}/{fmask_tiff}'\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(fmask_path) as src:\n",
    "            fmask_arr = src.read(1).flatten()\n",
    "    except Exception:\n",
    "        print('An fmask file could not be read:', fmask_path)\n",
    "        print('Marking that granule as bad data.')\n",
    "        # If we can't read the fmask, we need to ditch this granule\n",
    "        fin = [np.full((3660*3660,), -9999,\n",
    "                       dtype='int16') for _ in range(7)]\n",
    "        return fin\n",
    "\n",
    "    marked = []\n",
    "    for el in fmask_arr:\n",
    "        binary = '{0:b}'.format(el).zfill(8)\n",
    "        has_clouds = bool(int(binary[-2]))\n",
    "        has_adjacent = bool(int(binary[-3]))\n",
    "        has_shadow = bool(int(binary[-4]))\n",
    "        mark = ((has_clouds and mark_if_clouds) or\n",
    "              (has_adjacent and mark_if_adjacent) or\n",
    "              (has_shadow and mark_if_shadow))\n",
    "        marked.append(mark)    \n",
    "    cas_mask = np.array(marked)\n",
    "    \n",
    "    ### SNOW PROCESSING\n",
    "    if mark_if_snow:\n",
    "        band2 = 'B02'\n",
    "        tiff2 = f'{granule}.{band2}.tif'\n",
    "        path2 = f'{granule_path}/{tiff2}'\n",
    "        try:\n",
    "            with rasterio.open(path2) as src2:\n",
    "                arr2 = src2.read(1).flatten()\n",
    "        except Exception:\n",
    "            print('A file could not be read:', path2)\n",
    "            print('Cannot determine snow, so we cannot use this granule any further.')\n",
    "            print('Marking that granule as bad data.')\n",
    "            fin = [np.full((3660*3660,), -9999,\n",
    "                       dtype='int16') for _ in range(7)]\n",
    "            return fin\n",
    "        snow_mask = arr2>2000\n",
    "        final_mask = snow_mask | cas_mask\n",
    "    else:\n",
    "        final_mask = cas_mask\n",
    "    \n",
    "    ### For the 6 color bands,\n",
    "    ### Read into arrays and flatten\n",
    "    L30_dict = {'Blue':'B02', 'Green':'B03', 'Red':'B04',\n",
    "               'NIR':'B05', 'SWIR1':'B06', 'SWIR2':'B07'}\n",
    "    S30_dict = {'Blue':'B02', 'Green':'B03', 'Red':'B04',\n",
    "               'NIR':'B8A', 'SWIR1':'B11', 'SWIR2':'B12'}\n",
    "    bands = ['Blue','Green','Red','NIR','SWIR1','SWIR2']\n",
    "    DOY = int(granule[-15:-12])\n",
    "    sat = granule[4:7]\n",
    "    \n",
    "    filtered_granule = []\n",
    "    \n",
    "    for band in bands:\n",
    "        if sat == 'L30':\n",
    "            band_code = L30_dict[band]\n",
    "        if sat == 'S30':\n",
    "            band_code = S30_dict[band]\n",
    "        \n",
    "        band_tiff = f'{granule}.{band_code}.tif'\n",
    "        band_path = f'{granule_path}/{band_tiff}'\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(band_path) as src:\n",
    "                band_arr = src.read(1).astype('int16').flatten()\n",
    "        except Exception:\n",
    "            print('A band file could not be read:', band_path)\n",
    "            print('Marking that as bad data and continuing as normal with the rest of the files.')\n",
    "            # If we can't read this color band, mark it as all -9999\n",
    "            band_arr = np.full(final_mask.shape, -9999, dtype='int16')\n",
    "        \n",
    "        filtered_granule.append(band_arr)\n",
    "\n",
    "    filtered_granule.append(final_mask)\n",
    "    \n",
    "    ## Note: if we wanted to we could also return DOY and sat. Dunno if they will be helpful.\n",
    "    \n",
    "    ### return filtered_+granule as a list of 7 flat arrays\n",
    "    ## the 7 arrays are: blue, greem, red, NIR, SWIR1, SWIR2, mask\n",
    "    return filtered_granule "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2d926",
   "metadata": {},
   "source": [
    "### Try running that function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8102bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_granule_paths(tile='10SFH',\n",
    "                       year=2020,\n",
    "                       hls_dir='../data/hls_23feb23',\n",
    "                       sats=['L30','S30'],\n",
    "                       period_start=1,\n",
    "                       period_end=366):\n",
    "    \n",
    "    tile_slashes = f'{tile[:2]}/{tile[2]}/{tile[3]}/{tile[4]}'\n",
    "    \n",
    "    granule_paths = []\n",
    "    \n",
    "    for sat in sats:\n",
    "        path = f'{hls_dir}/{sat}/{year}/{tile_slashes}'\n",
    "        these_granules = os.listdir(path)\n",
    "        \n",
    "        this_sat_paths = []\n",
    "        for granule in these_granules:\n",
    "            DOY = int(granule[-15:-12])\n",
    "            if DOY>=period_start and DOY<=period_end:\n",
    "                this_sat_paths.append(path+'/'+granule)\n",
    "            \n",
    "        granule_paths += this_sat_paths\n",
    "    \n",
    "    return granule_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_paths = list_granule_paths(tile='10SFH',\n",
    "                       year=2020,\n",
    "                       hls_dir='../data/hls_23feb23',\n",
    "                       sats=['L30','S30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a54675",
   "metadata": {},
   "source": [
    "### Sweet, filtering that one granule took about 10 seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a385da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301798fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "granules_in_period = list_granule_paths(year=2020,\n",
    "                                       tile='10SFH',\n",
    "                                       period_start=91,\n",
    "                                       period_end=104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(granules_in_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [[] for _ in range(7)]\n",
    "print(list_of_lists)\n",
    "list_of_lists[0].append(88)\n",
    "list_of_lists[1].append(55)\n",
    "list_of_lists[0].append(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill list_of_lists with all the data to be composited\n",
    "list_of_lists = [[] for _ in range(7)]\n",
    "for granule_path in granules_in_period:\n",
    "    # Filter the granule\n",
    "    filtered_granule = filter_granule(granule_path)\n",
    "  \n",
    "    # Record all the bands and the mask\n",
    "    for i in range(7):\n",
    "        list_of_lists[i].append(filtered_granule[i])\n",
    "\n",
    "# Now list_of_lists has all the data we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2736ce",
   "metadata": {},
   "source": [
    "Note: defining list_of_lists as `[[]] * 7` will not work. If we do it that way, we have 7 views of hte same list: appending to one of the views will therefore append to the one shared list and be visible in all 7 views. \n",
    "\n",
    "Old interrogation of that below...\n",
    "\n",
    "What is in the mysterious list_of_lists?\n",
    "\n",
    "Conclusion: Within each lis, maybe none of the elements are the same.\n",
    "Next wuestion: is the first el of list 0 the same as the first element of list 1? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8727c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lis in enumerate(list_of_lists):\n",
    "    print(f'-- Info about list {i} --')\n",
    "    print(f'Length of list {i} is {len(lis)}')\n",
    "    print('Are some of the elements the same as each other? /n',\n",
    "          lis[0]==lis[4], lis[1]==lis[5], lis[2]==lis[6])\n",
    "    print('placeholder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    for j in range(28):\n",
    "        print(list_of_lists[i][j].all()==list_of_lists[i+1][j].all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_lists[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3352cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_lists[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77235da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da159e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take the median of each color band\n",
    "fmask_filter = np.array(list_of_lists[-1])\n",
    "composited = []\n",
    "for i in range(6):\n",
    "    marr = np.ma.array(list_of_lists[i])\n",
    "    marr.mask = (marr==-9999) | fmask_filter\n",
    "    this_band = np.ma.median(marr, axis=0).astype('int16')\n",
    "    composited.append(this_band.filled(-9999))\n",
    "    \n",
    "# Now composited contains the median-composited data for all bands\n",
    "# for just this period, and for just this tile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c7877",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "What happends if we try to take the median of four things that are masked?\n",
    "\n",
    "Answer (proof in other notebook): We get a masked value, where the data is 0. That is, the data value is 0 and the mask value is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12767871",
   "metadata": {},
   "outputs": [],
   "source": [
    "composited.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200dba25",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- put all lof the above into one function\n",
    "- run that giant function for all periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676fa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_one_period(tile='10SFH',\n",
    "                        year=2020,\n",
    "                        period_start=91,\n",
    "                        period_end=104,\n",
    "                        hls_dir='../data/hls_23feb23',\n",
    "                        sats=['L30','S30'],\n",
    "                        mark_if_clouds=True,\n",
    "                        mark_if_shadow=True,\n",
    "                        mark_if_adjacent=True,\n",
    "                        mark_if_snow=False):\n",
    "\n",
    "    granules_in_period = list_granule_paths(period_start=period_start,\n",
    "                                           period_end=period_end,\n",
    "                                           year=year,\n",
    "                                           tile=tile,\n",
    "                                           hls_dir=hls_dir,\n",
    "                                           sats=sats)\n",
    "\n",
    "    ## Fill list_of_lists with all the data to be composited\n",
    "    list_of_lists = [[] for _ in range(7)]\n",
    "    for granule_path in granules_in_period:\n",
    "        # Filter the granule\n",
    "        filtered_granule = filter_granule(granule_path,\n",
    "                                          mark_if_clouds=mark_if_clouds,\n",
    "                                          mark_if_shadow=mark_if_shadow,\n",
    "                                          mark_if_adjacent=mark_if_adjacent,\n",
    "                                          mark_if_snow=mark_if_snow)\n",
    "\n",
    "        # Record all the bands and the mask\n",
    "        for i in range(7):\n",
    "            list_of_lists[i].append(filtered_granule[i])\n",
    "\n",
    "    # Now take the median of each color band\n",
    "    fmask_filter = np.array(list_of_lists[-1])\n",
    "    composited = []\n",
    "    for i in range(6):\n",
    "        marr = np.ma.array(list_of_lists[i])\n",
    "        marr.mask = (marr==-9999) | fmask_filter\n",
    "        this_band = np.ma.median(marr, axis=0).astype('int16')\n",
    "        composited.append(this_band.filled(-9999))\n",
    "\n",
    "    # Now composited contains the median-composited data for all bands\n",
    "    # for just this period, and for just this tile.\n",
    "    return composited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77efc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "composited = composite_one_period(period_start=105,\n",
    "                    period_end=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "composited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297936bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define periods\n",
    "def get_period_schemes():\n",
    "\n",
    "    first_pd = (1,90)\n",
    "    last_pd = (301,366)\n",
    "    meat_5day = [(i,i+4) for i in range(91,300,5)]\n",
    "    meat_14day = [(i,i+13) for i in range(91,300,14)]\n",
    "\n",
    "    scheme_5day = [first_pd] + meat_5day + [last_pd]\n",
    "    scheme_14day = [first_pd] + meat_14day + [last_pd]\n",
    "    \n",
    "    return scheme_5day, scheme_14day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae9a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme_5day, scheme_14day = get_period_schemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0faa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_tile_year(tile,\n",
    "                            year,\n",
    "                            period_scheme,\n",
    "                            hls_dir='../data/hls_23feb23',\n",
    "                            sats=['L30','S30'],\n",
    "                            mark_if_clouds=True,\n",
    "                            mark_if_shadow=True,\n",
    "                            mark_if_adjacent=True,\n",
    "                            mark_if_snow=False):\n",
    "\n",
    "    feature_names = []\n",
    "    features = []\n",
    "\n",
    "    for period in period_scheme:\n",
    "        \n",
    "        period_start = period[0]\n",
    "        period_end = period[1]\n",
    "        \n",
    "        # NAMES\n",
    "        name_ohne_band = f'Refl_{period_start}_{period_end}'\n",
    "        bands = ['Blue','Green','Red','NIR','SWIR1','SWIR2']\n",
    "        names_this_period = [f'{name_ohne_band}_{band}' for band in bands]\n",
    "        feature_names += names_this_period\n",
    "        \n",
    "        # DATA\n",
    "        composited_this_period = composite_one_period(tile=tile,\n",
    "                            year=year,\n",
    "                            period_start=period_start,\n",
    "                            period_end=period_end,\n",
    "                            hls_dir=hls_dir,\n",
    "                            sats=sats,\n",
    "                            mark_if_clouds=mark_if_clouds,\n",
    "                            mark_if_shadow=mark_if_shadow,\n",
    "                            mark_if_adjacent=mark_if_adjacent,\n",
    "                            mark_if_snow=mark_if_snow)\n",
    "        features += composited_this_period\n",
    "        \n",
    "        print(f'Finished period ending DOY {period_end}.')\n",
    "        \n",
    "        # features is a list of flat numpy arrays\n",
    "        # feature_names is a list of strings\n",
    "        \n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7881f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished period ending DOY 90.\n",
      "Finished period ending DOY 104.\n",
      "Finished period ending DOY 118.\n",
      "Finished period ending DOY 132.\n",
      "Finished period ending DOY 146.\n",
      "Finished period ending DOY 160.\n",
      "Finished period ending DOY 174.\n",
      "Finished period ending DOY 188.\n",
      "Finished period ending DOY 202.\n",
      "Finished period ending DOY 216.\n",
      "Finished period ending DOY 230.\n",
      "Finished period ending DOY 244.\n",
      "Finished period ending DOY 258.\n",
      "Finished period ending DOY 272.\n",
      "Finished period ending DOY 286.\n",
      "Finished period ending DOY 300.\n",
      "Finished period ending DOY 366.\n"
     ]
    }
   ],
   "source": [
    "composited_10SFH_2020 = composite_tile_year(tile='10SFH',\n",
    "                   year=2020,\n",
    "                   period_scheme=scheme_14day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56771ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, feature_names = composited_10SFH_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a9362",
   "metadata": {},
   "source": [
    "### Next: write functions for *interpolating* and *exploring how many periods needed interpolating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2958eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = len(features[0])\n",
    "n_features = len(features)\n",
    "array_new = np.full(shape=(n_pixels,n_features),\n",
    "                    fill_value=-9999,dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae2b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sit tight! Fitting cubic splines on the 0th pixel...\n",
      "Sit tight! Fitting cubic splines on the 1000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 2000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 3000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 4000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 5000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 6000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 7000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 8000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 9000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 10000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 11000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 12000000th pixel...\n",
      "Sit tight! Fitting cubic splines on the 13000000th pixel...\n"
     ]
    }
   ],
   "source": [
    "for i_pixel in range(n_pixels): # for every pixel in the 14 million\n",
    "    if i_pixel%1000000 == 0:\n",
    "        print(f'Sit tight! Fitting cubic splines on the {i_pixel}th pixel...')\n",
    "    for band in range(6): # for each band in the 6\n",
    "        #range with skip # gather the data for this pixel this band\n",
    "        these_data = [features[j][i_pixel] for j in range(band, n_features, 6)]\n",
    "        ### these_data gets gathered from `features`\n",
    "        ### these_names get gathered from `feature_names`\n",
    "        meat = these_data[1:-1]\n",
    "\n",
    "        t = [t for t,refl in enumerate(meat) if refl!=-9999]\n",
    "        r = [refl for refl in meat if refl!=-9999]\n",
    "\n",
    "        f = CubicSpline(t,r)\n",
    "\n",
    "        t_new = np.arange(len(meat))\n",
    "        r_new = f(t_new).astype('int16')\n",
    "        r_sandwich = np.concatenate(([these_data[0]],\n",
    "                                    r_new,\n",
    "                                    [these_data[-1]]),\n",
    "                                    dtype='int16')\n",
    "        \n",
    "        # Above: fit a cubic spline\n",
    "        # get new refl values\n",
    "        \n",
    "        # Below: write new refls back into `features`\n",
    "        ##### just establish a new 2d Numpy array filled with -9999\n",
    "        ### this is where it *might* be more convenient to write this to a numpy array\n",
    "        ### could even be a 3-d Numpy array...\n",
    "        ### each output of the inner part of this for loop will be\n",
    "        ### a specific pixel-band, but all periods\n",
    "        ### nah, no 3d numpy array\n",
    "        # write these_names into final_names.. or do the data writing in such\n",
    "        # a way that the features are in the same order (using range with skip)\n",
    "        for k,j in enumerate(range(band, n_features, 6)):\n",
    "        # plunk each element of r_new out there into array_new\n",
    "            array_new[i_pixel,j] = r_sandwich[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f933e12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2732702400"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_new.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1887a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/Refl_10SFH_2020_14day.npy', array_new, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b627f4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 306,  648,  467, 3114, 2220, 1190,  260,  576,  387, 3302, 1651,\n",
       "        809,  396,  758,  930, 3128, 2536, 1333,  553,  933, 1523, 3128,\n",
       "       3100, 1667,  542,  784, 1069, 1609, 2585, 1962,  517,  742, 1007,\n",
       "       1534, 2669, 1984,  581,  807, 1059, 1693, 2905, 2100,  637,  873,\n",
       "       1174, 1838, 3104, 2222,  258,  336,  448,  683, 1423, 1597,  287,\n",
       "        382,  507,  763, 1568, 1752,  331,  440,  578,  867, 1720, 1875,\n",
       "        372,  506,  659,  983, 1852, 1891,  396,  531,  704, 1045, 1956,\n",
       "       1999,  411,  516,  701, 1125, 2200, 2192,  487,  617,  817, 1239,\n",
       "       2351, 2356,  540,  679,  907, 1335, 2452, 2398,  542,  699,  936,\n",
       "       1457, 2507, 2402], dtype=int16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_new[12055400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e535f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_new.any() == -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be5ae944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13395600, 102)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a29141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_new[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b42e5",
   "metadata": {},
   "source": [
    "## Gather the features of a particular band for cubic spline interpolation\n",
    "\n",
    "Recall that features rotate predictably: blue, green, red, nir, swir1, swir2, blue, green, red, nir, ....\n",
    "\n",
    "Therefore we know that features of index in range(0, end, 6) are all the blue features. And featuyres of index in range(1, end, 6) are all the green features. (2, end, 6) for red features. Etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1c40a",
   "metadata": {},
   "source": [
    "And we'd like to grab only the 1th feature through the second-to-last feature. How do we do this? ---> might be easiest to just grab all the red features, then when we're fitting the cubic spline only input features in the slice 1:-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather red features\n",
    "#red_features = [features[i] for i in range(2, len(features), 6)]\n",
    "\n",
    "red_features_one_pixel = [features[i][0] for i in range(2, len(features), 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ba4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do cubic spline on the 0th pixel, time series 1:-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9aced5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_features_one_pixel = [300,400,350,-9999,330,410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat = red_features_one_pixel[1:-1]\n",
    "\n",
    "t = [t for t,refl in enumerate(meat) if refl!=-9999]\n",
    "r = [refl for refl in meat if refl!=-9999]\n",
    "\n",
    "f = CubicSpline(t,r)\n",
    "\n",
    "t_new = np.arange(len(meat))\n",
    "\n",
    "meat\n",
    "\n",
    "t_new\n",
    "\n",
    "r_new = f(t_new).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0065e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write r_new into the official dataset\n",
    "# something here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62121b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0, 1, 2]\n",
    "y = [1, 3, 2]\n",
    "\n",
    "# use bc_type = 'natural' adds the constraints as we described above\n",
    "f = CubicSpline(x, y, bc_type='natural')\n",
    "x_new = np.linspace(0, 2, 100)\n",
    "y_new = f(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64098946",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [period[0] for period in period_scheme[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = refls_this_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = CubicSpline(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a741d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2830d179",
   "metadata": {},
   "source": [
    "We're just going to have to run CubicSpline() 14 million times. Oof.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf89dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pixel in range(len(features[0])): # for every pixel in the 14 million\n",
    "    for j_band in range(6): # for each band in the 6\n",
    "        #range with skip # gather the data for this pixel this band\n",
    "        ### these_data gets gatehred from `features`\n",
    "        ### these_names get gathered from `feature_names`\n",
    "        # fit a cubic spline\n",
    "        # get new refl values\n",
    "        # write new refls back into `features`\n",
    "        ##### just establish a new 2d Numpy array filled with -9999\n",
    "        ### this is where it *might* be more convenient to write this to a numpy array\n",
    "        ### could even be a 3-d Numpy array...\n",
    "        ### each output of the inner part of this for loop will be\n",
    "        ### a specific pixel-band, but all periods\n",
    "        ### nah, no 3d numpy array\n",
    "        # write these_names into final_names.. or do the data writing in such\n",
    "        # a way that the features are in the same order (using range with skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sandwich = np.concatenate(([12],r_new,[16]),dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "20001 % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd133e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(8).append(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4d8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "these_data = np.array([200,300,400,500,600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc68a473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "these_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec90ff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "these_data[1:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61455cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[these_data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c08c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sandwich = np.concatenate(([these_data[0]],\n",
    "                                    these_data[1:-1],\n",
    "                                    [these_data[-1]]),\n",
    "                                    dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "663befeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 300, 400, 500, 600], dtype=int16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f1454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b194b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2be44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd413f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a26c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9871c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import rasterio\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "def filter_granule(granule_path,\n",
    "                        mark_if_clouds=True,\n",
    "                        mark_if_shadow=True,\n",
    "                        mark_if_adjacent=True,\n",
    "                        mark_if_snow=False):\n",
    "\n",
    "    granule = granule_path[-34:]\n",
    "    \n",
    "    fmask_tiff = f'{granule}.Fmask.tif'\n",
    "    fmask_path = f'{granule_path}/{fmask_tiff}'\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(fmask_path) as src:\n",
    "            fmask_arr = src.read(1).flatten()\n",
    "    except Exception:\n",
    "        print('An fmask file could not be read:', fmask_path)\n",
    "        print('Marking that granule as bad data.')\n",
    "        # If we can't read the fmask, we need to ditch this granule\n",
    "        fin = [np.full((3660*3660,), -9999,\n",
    "                       dtype='int16') for _ in range(7)]\n",
    "        return fin\n",
    "\n",
    "    marked = []\n",
    "    for el in fmask_arr:\n",
    "        binary = '{0:b}'.format(el).zfill(8)\n",
    "        has_clouds = bool(int(binary[-2]))\n",
    "        has_adjacent = bool(int(binary[-3]))\n",
    "        has_shadow = bool(int(binary[-4]))\n",
    "        mark = ((has_clouds and mark_if_clouds) or\n",
    "              (has_adjacent and mark_if_adjacent) or\n",
    "              (has_shadow and mark_if_shadow))\n",
    "        marked.append(mark)    \n",
    "    cas_mask = np.array(marked)\n",
    "    \n",
    "    ### SNOW PROCESSING\n",
    "    if mark_if_snow:\n",
    "        band2 = 'B02'\n",
    "        tiff2 = f'{granule}.{band2}.tif'\n",
    "        path2 = f'{granule_path}/{tiff2}'\n",
    "        try:\n",
    "            with rasterio.open(path2) as src2:\n",
    "                arr2 = src2.read(1).flatten()\n",
    "        except Exception:\n",
    "            print('A file could not be read:', path2)\n",
    "            print('Cannot determine snow, so we cannot use this granule any further.')\n",
    "            print('Marking that granule as bad data.')\n",
    "            fin = [np.full((3660*3660,), -9999,\n",
    "                       dtype='int16') for _ in range(7)]\n",
    "            return fin\n",
    "        snow_mask = arr2>2000\n",
    "        final_mask = snow_mask | cas_mask\n",
    "    else:\n",
    "        final_mask = cas_mask\n",
    "    \n",
    "    ### For the 6 color bands,\n",
    "    ### Read into arrays and flatten\n",
    "    L30_dict = {'Blue':'B02', 'Green':'B03', 'Red':'B04',\n",
    "               'NIR':'B05', 'SWIR1':'B06', 'SWIR2':'B07'}\n",
    "    S30_dict = {'Blue':'B02', 'Green':'B03', 'Red':'B04',\n",
    "               'NIR':'B8A', 'SWIR1':'B11', 'SWIR2':'B12'}\n",
    "    bands = ['Blue','Green','Red','NIR','SWIR1','SWIR2']\n",
    "    DOY = int(granule[-15:-12])\n",
    "    sat = granule[4:7]\n",
    "    \n",
    "    filtered_granule = []\n",
    "    \n",
    "    for band in bands:\n",
    "        if sat == 'L30':\n",
    "            band_code = L30_dict[band]\n",
    "        if sat == 'S30':\n",
    "            band_code = S30_dict[band]\n",
    "        \n",
    "        band_tiff = f'{granule}.{band_code}.tif'\n",
    "        band_path = f'{granule_path}/{band_tiff}'\n",
    "\n",
    "        try:\n",
    "            with rasterio.open(band_path) as src:\n",
    "                band_arr = src.read(1).astype('int16').flatten()\n",
    "        except Exception:\n",
    "            print('A band file could not be read:', band_path)\n",
    "            print('Marking that as bad data and continuing as normal with the rest of the files.')\n",
    "            # If we can't read this color band, mark it as all -9999\n",
    "            band_arr = np.full(final_mask.shape, -9999, dtype='int16')\n",
    "        \n",
    "        filtered_granule.append(band_arr)\n",
    "\n",
    "    filtered_granule.append(final_mask)\n",
    "    \n",
    "    # return filtered_granule as a list of 7 flat arrays\n",
    "    # the 7 arrays are: blue, greem, red, NIR, SWIR1, SWIR2, mask\n",
    "    return filtered_granule \n",
    "\n",
    "def list_granule_paths(tile='10SFH',\n",
    "                       year=2020,\n",
    "                       hls_dir='../data/hls_23feb23',\n",
    "                       sats=['L30','S30'],\n",
    "                       period_start=1,\n",
    "                       period_end=366):\n",
    "    \n",
    "    tile_slashes = f'{tile[:2]}/{tile[2]}/{tile[3]}/{tile[4]}'\n",
    "    \n",
    "    granule_paths = []\n",
    "    \n",
    "    for sat in sats:\n",
    "        path = f'{hls_dir}/{sat}/{year}/{tile_slashes}'\n",
    "        these_granules = os.listdir(path)\n",
    "        \n",
    "        this_sat_paths = []\n",
    "        for granule in these_granules:\n",
    "            DOY = int(granule[-15:-12])\n",
    "            if DOY>=period_start and DOY<=period_end:\n",
    "                this_sat_paths.append(path+'/'+granule)\n",
    "            \n",
    "        granule_paths += this_sat_paths\n",
    "    \n",
    "    return granule_paths\n",
    "\n",
    "def composite_one_period(tile='10SFH',\n",
    "                        year=2020,\n",
    "                        period_start=91,\n",
    "                        period_end=104,\n",
    "                        hls_dir='../data/hls_23feb23',\n",
    "                        sats=['L30','S30'],\n",
    "                        mark_if_clouds=True,\n",
    "                        mark_if_shadow=True,\n",
    "                        mark_if_adjacent=True,\n",
    "                        mark_if_snow=False):\n",
    "\n",
    "    granules_in_period = list_granule_paths(period_start=period_start,\n",
    "                                           period_end=period_end,\n",
    "                                           year=year,\n",
    "                                           tile=tile,\n",
    "                                           hls_dir=hls_dir,\n",
    "                                           sats=sats)\n",
    "\n",
    "    ## Fill list_of_lists with all the data to be composited\n",
    "    list_of_lists = [[] for _ in range(7)]\n",
    "    for granule_path in granules_in_period:\n",
    "        # Filter the granule\n",
    "        filtered_granule = filter_granule(granule_path,\n",
    "                                          mark_if_clouds=mark_if_clouds,\n",
    "                                          mark_if_shadow=mark_if_shadow,\n",
    "                                          mark_if_adjacent=mark_if_adjacent,\n",
    "                                          mark_if_snow=mark_if_snow)\n",
    "\n",
    "        # Record all the bands and the mask\n",
    "        for i in range(7):\n",
    "            list_of_lists[i].append(filtered_granule[i])\n",
    "\n",
    "    # Now take the median of each color band\n",
    "    fmask_filter = np.array(list_of_lists[-1])\n",
    "    composited = []\n",
    "    for i in range(6):\n",
    "        marr = np.ma.array(list_of_lists[i])\n",
    "        marr.mask = (marr==-9999) | fmask_filter\n",
    "        this_band = np.ma.median(marr, axis=0).astype('int16')\n",
    "        composited.append(this_band.filled(-9999))\n",
    "\n",
    "    # Now composited contains the median-composited data for all bands\n",
    "    # for just this period, and for just this tile.\n",
    "    return composited\n",
    "\n",
    "def get_period_schemes():\n",
    "\n",
    "    first_pd = (1,90)\n",
    "    last_pd = (301,366)\n",
    "    meat_5day = [(i,i+4) for i in range(91,300,5)]\n",
    "    meat_14day = [(i,i+13) for i in range(91,300,14)]\n",
    "\n",
    "    scheme_5day = [first_pd] + meat_5day + [last_pd]\n",
    "    scheme_14day = [first_pd] + meat_14day + [last_pd]\n",
    "    \n",
    "    return scheme_5day, scheme_14day\n",
    "\n",
    "\n",
    "def composite_tile_year(tile,\n",
    "                            year,\n",
    "                            period_scheme,\n",
    "                            hls_dir='../data/hls_23feb23',\n",
    "                            sats=['L30','S30'],\n",
    "                            mark_if_clouds=True,\n",
    "                            mark_if_shadow=True,\n",
    "                            mark_if_adjacent=True,\n",
    "                            mark_if_snow=False):\n",
    "\n",
    "    feature_names = []\n",
    "    features = []\n",
    "\n",
    "    for period in period_scheme:\n",
    "        \n",
    "        period_start = period[0]\n",
    "        period_end = period[1]\n",
    "        \n",
    "        # NAMES\n",
    "        name_ohne_band = f'Refl_{period_start}_{period_end}'\n",
    "        bands = ['Blue','Green','Red','NIR','SWIR1','SWIR2']\n",
    "        names_this_period = [f'{name_ohne_band}_{band}' for band in bands]\n",
    "        feature_names += names_this_period\n",
    "        \n",
    "        # DATA\n",
    "        composited_this_period = composite_one_period(tile=tile,\n",
    "                            year=year,\n",
    "                            period_start=period_start,\n",
    "                            period_end=period_end,\n",
    "                            hls_dir=hls_dir,\n",
    "                            sats=sats,\n",
    "                            mark_if_clouds=mark_if_clouds,\n",
    "                            mark_if_shadow=mark_if_shadow,\n",
    "                            mark_if_adjacent=mark_if_adjacent,\n",
    "                            mark_if_snow=mark_if_snow)\n",
    "        features += composited_this_period\n",
    "        \n",
    "        print(f'Finished period ending DOY {period_end}.')\n",
    "        \n",
    "        # features is a list of flat numpy arrays\n",
    "        # feature_names is a list of strings\n",
    "        \n",
    "    return features, feature_names\n",
    "\n",
    "\n",
    "def interpolate_cubic_spline(features):\n",
    "\n",
    "    n_pixels = len(features[0])\n",
    "    n_features = len(features)\n",
    "    array_new = np.full(shape=(n_pixels,n_features),\n",
    "                        fill_value=-9999,dtype='int16')\n",
    "\n",
    "    for i_pixel in range(n_pixels): # for every pixel in the 14 million\n",
    "        if i_pixel%1000000 == 0:\n",
    "            print(f'Sit tight! Fitting cubic splines on the {i_pixel}th pixel...')\n",
    "        for band in range(6): # for each band in the 6\n",
    "            # gather the data for this pixel this band\n",
    "            these_data = [features[j][i_pixel] for j in range(band, n_features, 6)]\n",
    "            \n",
    "            meat = these_data[1:-1]\n",
    "\n",
    "            t = [t for t,refl in enumerate(meat) if refl!=-9999]\n",
    "            r = [refl for refl in meat if refl!=-9999]\n",
    "\n",
    "            f = CubicSpline(t,r)\n",
    "\n",
    "            t_new = np.arange(len(meat))\n",
    "            r_new = f(t_new).astype('int16')\n",
    "            r_sandwich = np.concatenate(([these_data[0]],\n",
    "                                        r_new,\n",
    "                                        [these_data[-1]]),\n",
    "                                        dtype='int16')\n",
    "\n",
    "            # write the filled features into array_new in the same order\n",
    "            for k,j in enumerate(range(band, n_features, 6)):\n",
    "            # distribute each element of r_new out into array_new\n",
    "                array_new[i_pixel,j] = r_sandwich[k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa0b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pygdal-skl)",
   "language": "python",
   "name": "pygdal-skl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
